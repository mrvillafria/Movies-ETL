# ETL - Extract, Transform, Load

## Overview of Project
For this week's project, we are using the Extract, Transform, Load (ETL) process to create data pipelines. The ETL process moves data from a source to a destination, transforms and cleans the data, and loads the finished data. We'll be using Python and Pandas to analyze and perform data wrangling. To store our data, we will use Postgres SQL. 

### Purpose
The purpose of this week's project was to help Britta, a member of the Amazing Prime video team, create datasets for a hackathon. The hackathon asking the participants to help predict movie popularity. Amazing Prime's goal would be to try to predict if low budget movies will become popular so they can try to buy the steaming rights as a lower price. The two data sources are movies released since 1990 from Wikipedia and rating data from Movie Land.